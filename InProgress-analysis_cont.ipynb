{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Points(): \n",
    "    def __init__(self):\n",
    "        self.frameNuber = -1\n",
    "        self.index = -1\n",
    "        self.xLeft = []\n",
    "        self.xRight = []\n",
    "        self.yLeft = []\n",
    "        self.yRight = []\n",
    "        self.cLeft = []\n",
    "        self.cRight = []\n",
    "        self.xBody = []\n",
    "        self.yBody = []\n",
    "        self.cBody = []\n",
    "        self.xFace = []\n",
    "        self.yFace = []\n",
    "        self.xPalmLeft = 0\n",
    "        self.xPalmRight = 0\n",
    "        self.yPalmLeft = 0\n",
    "        self.yPalmRight = 0\n",
    "        self.minDist = sys.float_info.max\n",
    "#orientation = orientation between thumbs and other fingers\n",
    "        self.lOrientation = []\n",
    "        self.rOrientation = []\n",
    "        self.xLCenter = 0\n",
    "        self.xRCenter = 0\n",
    "        self.yLCenter = 0\n",
    "        self.yRCenter = 0\n",
    "        self.frameDistance = 0 #distance from the current word to the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LoadTransition():\n",
    "    trans = []\n",
    "#     files = glob.glob(\"E:/yulia/openpose/transition3/*.json\") \n",
    "    files = glob.glob(\"../jsons/transitions/*.json\")\n",
    "#     files = glob.glob(\"F:/[[][[]MASTER[]][]]/thesis/openpose/transition/*.json\")\n",
    "    ctrTrans = 0\n",
    "    for f in files:\n",
    "        fName = os.path.basename(f)\n",
    "        number = re.split(\"(\\d+)\", fName)\n",
    "        number = int(number[1])\n",
    "        trans.append(Points())\n",
    "        with open(f) as df:\n",
    "            data = json.load(df)\n",
    "            frameNumber = number\n",
    "            trans[ctrTrans].frameNumber = number\n",
    "            trans[ctrTrans].index = ctrTrans\n",
    "            #each hand has 21 points. x,y,c --> 0 to 62\n",
    "            trans[ctrTrans].xBody.append(data['people'][0]['pose_keypoints_2d'][4*3])\n",
    "            trans[ctrTrans].xBody.append(data['people'][0]['pose_keypoints_2d'][7*3])\n",
    "            trans[ctrTrans].yBody.append(data['people'][0]['pose_keypoints_2d'][4*3])\n",
    "            trans[ctrTrans].yBody.append(data['people'][0]['pose_keypoints_2d'][7*3])\n",
    "            \n",
    "            trans[ctrTrans].xPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][0])\n",
    "            trans[ctrTrans].yPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][1])\n",
    "            trans[ctrTrans].xPalmRight = (data['people'][0]['hand_right_keypoints_2d'][0])\n",
    "            trans[ctrTrans].yPalmRight = (data['people'][0]['hand_right_keypoints_2d'][1])\n",
    "            \n",
    "            xLeft = []; yLeft = []; xRight = []; yRight = []\n",
    "            for j in range(4,21,4):\n",
    "                xLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3])\n",
    "                yLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3+1])\n",
    "                xRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3])\n",
    "                yRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3+1])\n",
    "            for j in range(1,5):\n",
    "                trans[ctrTrans].lOrientation.append(np.cross([xLeft[0] , yLeft[0]] ,[xLeft[j] , yLeft[j]]))\n",
    "                trans[ctrTrans].rOrientation.append(np.cross([xRight[0], yRight[0]],[xRight[j],yRight[j]]))\n",
    "            trans[ctrTrans].xLCenter = np.sum(xLeft)/5\n",
    "            trans[ctrTrans].xRCenter = np.sum(xRight)/5\n",
    "            trans[ctrTrans].yLCenter = np.sum(yLeft)/5\n",
    "            trans[ctrTrans].yRCenter = np.sum(yRight)/5\n",
    "        ctrTrans+=1\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans = LoadTransition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a sentenceafraid agree bachelor baby background\n"
     ]
    }
   ],
   "source": [
    "input_text = str(input(\"enter a sentence\"))\n",
    "input_text = input_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = \"F:/[[MASTER]]/thesis/openpose/\"\n",
    "dir_path = \"../jsons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in range(len(input_text)):\n",
    "    ctr = 0\n",
    "    words.append([])\n",
    "    for filename in os.listdir(dir_path+input_text[i]):\n",
    "        number = int(re.split(\"(\\d+)\", os.path.basename(filename))[1])\n",
    "        if (number < 3 or number >= len(os.listdir(dir_path+input_text[i]))-3):\n",
    "            words[i].append(Points())\n",
    "            with open(dir_path +input_text[i]+\"/\"+input_text[i]+\"_\"+ ((str)(number)).zfill(12)+\"_keypoints.json\") as df:\n",
    "                data = json.load(df)\n",
    "                xLeft = []; yLeft = []; xRight = []; yRight = []\n",
    "                for j in range(4,21,4):\n",
    "                    xLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3])\n",
    "                    yLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3+1])\n",
    "                    xRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3])\n",
    "                    yRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3+1])\n",
    "                for j in range(1,5):\n",
    "                    words[i][ctr].lOrientation.append(np.cross([xLeft[0] , yLeft[0]] ,[xLeft[j] , yLeft[j]]))\n",
    "                    words[i][ctr].rOrientation.append(np.cross([xRight[0], yRight[0]],[xRight[j],yRight[j]]))\n",
    "                words[i][ctr].xBody.append(data['people'][0]['pose_keypoints_2d'][4*3])\n",
    "                words[i][ctr].xBody.append(data['people'][0]['pose_keypoints_2d'][7*3])\n",
    "                words[i][ctr].yBody.append(data['people'][0]['pose_keypoints_2d'][4*3])\n",
    "                words[i][ctr].yBody.append(data['people'][0]['pose_keypoints_2d'][7*3])\n",
    "                                 \n",
    "                words[i][ctr].xPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][0])\n",
    "                words[i][ctr].yPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][1])\n",
    "                words[i][ctr].xPalmRight = (data['people'][0]['hand_right_keypoints_2d'][0])\n",
    "                words[i][ctr].yPalmRight = (data['people'][0]['hand_right_keypoints_2d'][1])\n",
    "                \n",
    "                \n",
    "                words[i][ctr].xLCenter = np.sum(xLeft)/5\n",
    "                words[i][ctr].xRCenter = np.sum(xRight)/5\n",
    "                words[i][ctr].yLCenter = np.sum(yLeft)/5\n",
    "                words[i][ctr].yRCenter = np.sum(yRight)/5\n",
    "                \n",
    "                ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Distance(object):\n",
    "    def __init__(self):\n",
    "        self.distance = 0\n",
    "        self.From = -1\n",
    "        self.index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(framesA, framesB, framesC):\n",
    "    arr_distance = []\n",
    "    frames = framesA+framesB\n",
    "    \n",
    "    min_x_L = min(frames[2].xLCenter, frames[3].xLCenter) \n",
    "    max_x_L = max(frames[2].xLCenter, frames[3].xLCenter)\n",
    "    min_y_L = min(frames[2].yLCenter, frames[3].yLCenter)\n",
    "    max_y_L = max(frames[2].yLCenter, frames[3].yLCenter)\n",
    "    \n",
    "    min_x_R = min(frames[2].xRCenter, frames[3].xRCenter)\n",
    "    max_x_R = max(frames[2].xRCenter, frames[3].xRCenter)\n",
    "    min_y_R = min(frames[2].yRCenter, frames[3].yRCenter)\n",
    "    max_y_R = max(frames[2].yRCenter, frames[3].yRCenter)\n",
    "    \n",
    "    for i in range(len(framesC)):\n",
    "        const = 0.7\n",
    "        ctrConst = 0.1\n",
    "        temp_distance = 0\n",
    "        for j in range(len(frames)):\n",
    "            wrist_distance = 0\n",
    "            for k in range(len(framesC[i].xBody)):\n",
    "                wristX = framesC[i].xBody[k]-frames[j].xBody[k]\n",
    "                wristY = framesC[i].yBody[k]-frames[j].yBody[k]\n",
    "                wrist_distance += np.sqrt(np.power(wristX,2)+np.power(wristY,2))\n",
    "            orientation = 0\n",
    "            for k in range(0,4):\n",
    "                if framesC[i].lOrientation[k] * frames[j].lOrientation[k] < 0:\n",
    "                    orientation += 1\n",
    "                if framesC[i].rOrientation[k] * frames[j].rOrientation[k] < 0:\n",
    "                    orientation += 1\n",
    "            palm_left =np.sqrt(np.power(framesC[i].xPalmLeft-frames[j].xPalmLeft,2)+np.power(framesC[i].yPalmLeft-frames[j].yPalmLeft,2))\n",
    "            palm_right=np.sqrt(np.power(framesC[i].xPalmRight-frames[j].xPalmRight,2)+np.power(framesC[i].yPalmRight-frames[j].yPalmRight,2))\n",
    "            palm_distance =  palm_left + palm_right\n",
    "            if orientation >1:\n",
    "                palm_distance += 50\n",
    "            if j >= 3:\n",
    "                ctrConst = -0.2\n",
    "            const += ctrConst\n",
    "            temp_distance += const * palm_distance\n",
    "        arr_distance.append(Distance())\n",
    "        arr_distance[i].From = framesC[i].frameNumber\n",
    "        arr_distance[i].distance = (temp_distance/10)\n",
    "        arr_distance[i].palm_left = palm_left\n",
    "        arr_distance[i].palm_right = palm_right\n",
    "        arr_distance[i].index = i\n",
    "    arr_distance.sort(key = lambda x: x.distance, reverse = False)\n",
    "#     for i in range(0,10):\n",
    "#         print(str(arr_distance[i].From) + \" - \" + str(arr_distance[i].distance) + \" / \" + str(arr_distance[i].palm_left) + \" | \" + str(arr_distance[i].palm_right))\n",
    "#     print(arr_distance[0].From)\n",
    "    for i in range(len(arr_distance)):\n",
    "        if min_x_L-20 <= framesC[arr_distance[i].index].xLCenter <= max_x_L+20:\n",
    "            if min_y_L-20 <= framesC[arr_distance[i].index].yLCenter <= max_y_L+20:\n",
    "                if min_x_R-20 <= framesC[arr_distance[i].index].xRCenter <= max_x_R+20:\n",
    "                    if min_y_R-20 <= framesC[arr_distance[i].index].yRCenter <= max_y_R+20:\n",
    "                        return arr_distance[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_smoothing(frameA, frameB):\n",
    "    new_img = cv2.addWeighted(frameA, 0.5, frameB, 0.5, 0)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_left(frameA, frameB, frameT, threshold):\n",
    "    frame = distance(frameA, frameB, frameT)\n",
    "#     print(frame.From)\n",
    "    if frame:\n",
    "        if(frame.distance >= threshold):\n",
    "            if threshold == 1000:\n",
    "                threshold = frame.distance\n",
    "            else:\n",
    "                return\n",
    "        new_frameB = deepcopy(frameB)\n",
    "        new_frameB.insert(0,deepcopy(frameT[frame.index]))\n",
    "        new_frameB.pop()\n",
    "        temp.insert(0, frameT[frame.index])\n",
    "        frameT.pop(frame.index)\n",
    "        divide_left(frameA,new_frameB,frameT,threshold-150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_right(frameA,frameB,frameT, threshold):\n",
    "    frame = distance(frameA, frameB, frameT)\n",
    "#     print(\" - \" + str(frame.From))\n",
    "    if frame:\n",
    "        if(frame.distance >= threshold):\n",
    "            if threshold == 1000:\n",
    "                threshold = frame.distance\n",
    "            else:\n",
    "                return\n",
    "        new_frameA = deepcopy(frameA)\n",
    "        new_frameA.append(deepcopy(frameT[frame.index]))\n",
    "        new_frameA.pop(0)\n",
    "        temp.append(frameT[frame.index])\n",
    "        frameT.pop(frame.index)\n",
    "        divide_right(new_frameA, frameB, frameT, threshold-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 1000\n",
    "temp = []\n",
    "transition  = []\n",
    "for i in range(0, len(words)-1):\n",
    "    divide_left([deepcopy(words[i][3]),deepcopy(words[i][4]),deepcopy(words[i][5])],[deepcopy(words[i+1][0]),deepcopy(words[i+1][1]),deepcopy(words[i+1][2])],deepcopy(trans), threshold)\n",
    "    divide_right([deepcopy(words[i][3]),deepcopy(words[i][4]),deepcopy(words[i][5])],[deepcopy(words[i+1][0]),deepcopy(words[i+1][1]),deepcopy(words[i+1][2])],deepcopy(trans), threshold)\n",
    "    transition.append(temp.copy())\n",
    "    temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804\n",
      "1796\n",
      "1808\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "404\n",
      "410\n",
      "411\n",
      "414\n",
      "413\n",
      "412\n",
      "415\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(transition[0])):\n",
    "    print(transition[0][i].frameNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readVideo(vid):\n",
    "    cap = vid\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "    \n",
    "    fc = 0\n",
    "    ret = True\n",
    "\n",
    "    while (fc < frameCount  and ret):\n",
    "        ret, buf[fc] = cap.read()\n",
    "        fc += 1\n",
    "\n",
    "    cap.release()\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLargeVideo(vid, trans_idx):\n",
    "    cap = vid\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    buf = np.empty((len(trans_idx), frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "    \n",
    "    fc = 0\n",
    "    ret = True\n",
    "\n",
    "    while (fc < frameCount  and ret):\n",
    "        ret, frame = cap.read()\n",
    "        for i in range(len(trans_idx)):\n",
    "            if fc == trans_idx[i].frameNumber:\n",
    "                buf[i] = frame\n",
    "        fc += 1\n",
    "    cap.release()\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read transition video and save to array of images\n",
    "videos = []\n",
    "for i in range(len(input_text)):\n",
    "#     videos.append(readVideo(cv2.VideoCapture('F:/[[MASTER]]/thesis/ASL/'+input_text[i]+'.mp4')))\n",
    "    videos.append(readVideo(cv2.VideoCapture('../ASL/'+input_text[i]+'.mp4')))\n",
    "# trans_img = readVideo(cv2.VideoCapture('F:/[[MASTER]]/thesis/ASL/transition.mp4'))\n",
    "# trans_img = readVideo(cv2.VideoCapture('/home/yulia/Documents/ASL/transitions.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "written_trans = []\n",
    "for i in range(0, len(transition)):\n",
    "    written_trans.append([])\n",
    "    written_trans[i] = (readLargeVideo(cv2.VideoCapture('../ASL/transitions.mp4'),transition[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_optical_flow(frameA, frameB):\n",
    "    \n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict( maxCorners = 100,\n",
    "                           qualityLevel = 0.3,\n",
    "                           minDistance = 7,\n",
    "                           blockSize = 7 )\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    # Create some random colors\n",
    "    color = np.random.randint(0,255,(100,3))\n",
    "    # Take first frame and find corners in it\n",
    "    old_frame = frameA\n",
    "    old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "    p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)\n",
    "    frame = frameB\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "   \n",
    "    \n",
    "    \n",
    "#     cv2.imshow('frame2',bgr)\n",
    "#     k = cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(0, len(input_text)):\n",
    "    for j in range(0, len(videos[i])):\n",
    "        output.append(videos[i][j])\n",
    "    if i < len(input_text)-1:\n",
    "        prev = videos[i][j]\n",
    "        for j in range(0, len(written_trans[i])):\n",
    "            if j > 0:\n",
    "                prev = written_trans[i][j-1]\n",
    "            output.append(trans_smoothing(prev, written_trans[i][j]))\n",
    "            output.append(written_trans[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "height,width,channels = videos[0][0].shape\n",
    "# out = cv2.VideoWriter('E:/yulia/output/trial-bener-1.mp4',cv2.VideoWriter_fourcc('F','M','P', '4'), 10, (width,height))\n",
    "# out = cv2.VideoWriter('F:/[[MASTER]]/thesis/outputThesis/trial-amin-16.mp4',cv2.VideoWriter_fourcc('F','M','P', '4'), 20, (width,height))\n",
    "out = cv2.VideoWriter('../outputThesis/trial-amin-18.mp4',cv2.VideoWriter_fourcc('F','M','P', '4'), 20, (width,height))\n",
    "for i in range(0, len(output)):\n",
    "        out.write(output[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "written_trans[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
