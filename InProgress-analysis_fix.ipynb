{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from tkinter import *\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a class to store the body keypoints from JSON\n",
    "class Points(): \n",
    "    def __init__(self):\n",
    "        self.frameNumber = -1\n",
    "        self.index = -1\n",
    "        self.xLeft = []\n",
    "        self.xRight = []\n",
    "        self.yLeft = []\n",
    "        self.yRight = []\n",
    "        self.xBody = []\n",
    "        self.yBody = []\n",
    "        self.xPalmLeft = 0\n",
    "        self.xPalmRight = 0\n",
    "        self.yPalmLeft = 0\n",
    "        self.yPalmRight = 0\n",
    "        #orientation = orientation between thumbs and other fingers\n",
    "        self.lOrientation = []\n",
    "        self.rOrientation = []\n",
    "        self.xLCenter = 0\n",
    "        self.xRCenter = 0\n",
    "        self.yLCenter = 0\n",
    "        self.yRCenter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LoadTransition():\n",
    "    trans = []\n",
    "    #get transition json files\n",
    "    files = glob.glob(\"../jsons/transitions/*.json\")\n",
    "    ctrTrans = 0\n",
    "    for f in files:\n",
    "        fName = os.path.basename(f)\n",
    "        #number is the transition frame number. assumed that a json filename represent the frame number\n",
    "        number = re.split(\"(\\d+)\", fName)\n",
    "        number = int(number[1])\n",
    "        trans.append(Points())\n",
    "        with open(f) as df:\n",
    "            data = json.load(df)\n",
    "            frameNumber = number\n",
    "            #frame number is the order of the frame, index is the index of the array because it will be sorted so the order might be change\n",
    "            trans[ctrTrans].frameNumber = number\n",
    "            trans[ctrTrans].index = ctrTrans\n",
    "            \n",
    "            #get the wrist keypoint (index 4 and 7) from the json\n",
    "            trans[ctrTrans].xBody.append(data['people'][0]['pose_keypoints_2d'][4*3])\n",
    "            trans[ctrTrans].xBody.append(data['people'][0]['pose_keypoints_2d'][7*3])\n",
    "            trans[ctrTrans].yBody.append(data['people'][0]['pose_keypoints_2d'][4*3+1])\n",
    "            trans[ctrTrans].yBody.append(data['people'][0]['pose_keypoints_2d'][7*3+1])\n",
    "            \n",
    "            \n",
    "            #get the palm center data from the hand json index 0\n",
    "            trans[ctrTrans].xPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][0])\n",
    "            trans[ctrTrans].yPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][1])\n",
    "            trans[ctrTrans].xPalmRight = (data['people'][0]['hand_right_keypoints_2d'][0])\n",
    "            trans[ctrTrans].yPalmRight = (data['people'][0]['hand_right_keypoints_2d'][1])\n",
    "            \n",
    "            xLeft = []; yLeft = []; xRight = []; yRight = []\n",
    "            #get the fingertip positions. (index 4,8,12,16,20 from openpose. each keypoint has x,y,c)\n",
    "            for j in range(4,21,4):\n",
    "                xLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3])\n",
    "                yLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3+1])\n",
    "                xRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3])\n",
    "                yRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3+1])\n",
    "            #calculate the fingertip orientation\n",
    "            for j in range(1,5):\n",
    "                trans[ctrTrans].lOrientation.append(np.cross([xLeft[0] , yLeft[0]] ,[xLeft[j] , yLeft[j]]))\n",
    "                trans[ctrTrans].rOrientation.append(np.cross([xRight[0], yRight[0]],[xRight[j],yRight[j]]))\n",
    "            \n",
    "            #Center are the average of 5 fingertips from a hand\n",
    "            trans[ctrTrans].xLCenter = np.sum(xLeft)/5\n",
    "            trans[ctrTrans].xRCenter = np.sum(xRight)/5\n",
    "            trans[ctrTrans].yLCenter = np.sum(yLeft)/5\n",
    "            trans[ctrTrans].yRCenter = np.sum(yRight)/5\n",
    "        ctrTrans+=1\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "transition  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define the distance class. the distance value is stored in distance property.\n",
    "class Distance(object):\n",
    "    def __init__(self):\n",
    "        self.distance = 0\n",
    "        self.From = -1\n",
    "        self.index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(framesA, framesB, framesC):\n",
    "    arr_distance = []\n",
    "    frames = framesA+framesB\n",
    "    \n",
    "    #get the trajectory range from the palmcenter, retrieved from the avg of fingertips position\n",
    "    min_x_L = min(frames[2].xLCenter, frames[3].xLCenter) \n",
    "    max_x_L = max(frames[2].xLCenter, frames[3].xLCenter)\n",
    "    min_y_L = min(frames[2].yLCenter, frames[3].yLCenter)\n",
    "    max_y_L = max(frames[2].yLCenter, frames[3].yLCenter)   \n",
    "    min_x_R = min(frames[2].xRCenter, frames[3].xRCenter)\n",
    "    max_x_R = max(frames[2].xRCenter, frames[3].xRCenter)\n",
    "    min_y_R = min(frames[2].yRCenter, frames[3].yRCenter)\n",
    "    max_y_R = max(frames[2].yRCenter, frames[3].yRCenter)\n",
    "    \n",
    "    for i in range(len(framesC)):\n",
    "        const = 0.7 #initial weight\n",
    "        ctrConst = 0.1 #variabe to change the weight\n",
    "        temp_distance = 0\n",
    "        flag = False\n",
    "        for j in range(len(frames)):\n",
    "            wrist_distance = 0\n",
    "            \n",
    "            #get the L2 distance of wrist\n",
    "            for k in range(len(framesC[i].xBody)):\n",
    "                wristX = framesC[i].xBody[k]-frames[j].xBody[k]\n",
    "                wristY = framesC[i].yBody[k]-frames[j].yBody[k]\n",
    "                wrist_distance += np.sqrt(np.power(wristX,2)+np.power(wristY,2))\n",
    "            \n",
    "            #get the L2 distance of palm center\n",
    "            palm_left =np.sqrt(np.power(framesC[i].xPalmLeft-frames[j].xPalmLeft,2)+np.power(framesC[i].yPalmLeft-frames[j].yPalmLeft,2))\n",
    "            palm_right=np.sqrt(np.power(framesC[i].xPalmRight-frames[j].xPalmRight,2)+np.power(framesC[i].yPalmRight-frames[j].yPalmRight,2))\n",
    "            palm_distance =  palm_left + palm_right\n",
    "            \n",
    "            #check the orientation difference from 2 frames. if different, then the distance will be increased.\n",
    "            orientation = 0\n",
    "            for k in range(0,4):\n",
    "                if framesC[i].lOrientation[k] * frames[j].lOrientation[k] < 0:\n",
    "                    orientation += 1\n",
    "                if framesC[i].rOrientation[k] * frames[j].rOrientation[k] < 0:\n",
    "                    orientation += 1\n",
    "            if orientation >1:\n",
    "                palm_distance += 50\n",
    "            \n",
    "            #change the weight\n",
    "            if j >= (int)(len(frames)/2):\n",
    "                ctrConst = -0.2\n",
    "            const += ctrConst\n",
    "            \n",
    "            #the total distance from the iteration is saved in this variable\n",
    "            temp_distance += const * palm_distance\n",
    "            \n",
    "            #check if the frames compared is same, then skip the iteration\n",
    "            if(palm_left == 0.0 and palm_right == 0.0 and wrist_distance == 0.0):\n",
    "                flag = True\n",
    "        if(flag):\n",
    "            continue\n",
    "        else:\n",
    "            #append the distance array by the calculation result\n",
    "            arr_distance.append(Distance())\n",
    "            arr_distance[len(arr_distance)-1].From = framesC[i].frameNumber\n",
    "            arr_distance[len(arr_distance)-1].distance = (temp_distance) \n",
    "            arr_distance[len(arr_distance)-1].palm_left = palm_left\n",
    "            arr_distance[len(arr_distance)-1].palm_right = palm_right\n",
    "            arr_distance[len(arr_distance)-1].index = i\n",
    "    #sort the distance array by the distance\n",
    "    arr_distance.sort(key = lambda x: x.distance, reverse = False)\n",
    "    \n",
    "    #if the trajectory satisfied, return the frame with the smallest distance\n",
    "    for i in range(len(arr_distance)):\n",
    "        if min_x_L-20 <= framesC[arr_distance[i].index].xLCenter <= max_x_L+20:\n",
    "            if min_y_L-20 <= framesC[arr_distance[i].index].yLCenter <= max_y_L+20:\n",
    "                if min_x_R-20 <= framesC[arr_distance[i].index].xRCenter <= max_x_R+20:\n",
    "                    if min_y_R-20 <= framesC[arr_distance[i].index].yRCenter <= max_y_R+20:\n",
    "                        return arr_distance[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crossfading function\n",
    "def trans_smoothing(frameA, frameB, weightA):\n",
    "    new_img = cv2.addWeighted(frameA, weightA, frameB, 1.0-weightA, 0)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_left(frameA, frameB, frameT, threshold):\n",
    "    global temp\n",
    "    #call distance function\n",
    "    frame = distance(frameA, frameB, frameT)\n",
    "    #if the returned frame is available, continue the iteration\n",
    "    if frame:\n",
    "        #at least one frame is returned, after get the 1st frame, the threshold is changed into the 1st distance\n",
    "        if(frame.distance >= threshold):\n",
    "            if threshold == 1000:\n",
    "                threshold = frame.distance\n",
    "            else:\n",
    "                return\n",
    "        \n",
    "        new_frameB = deepcopy(frameB)\n",
    "        #insert the returned frame into the 1st index of frameB, the last index of frameB is removed\n",
    "        new_frameB.insert(0,deepcopy(frameT[frame.index]))\n",
    "        new_frameB.pop()\n",
    "        #insert the returned frame into the 1st index of temp. temp is a global variable to store the transition sequence\n",
    "        temp.insert(0, frameT[frame.index])\n",
    "        frameT.pop(frame.index)\n",
    "        #recursively call the function\n",
    "        divide_left(frameA,new_frameB,frameT,threshold-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_right(frameA,frameB,frameT, threshold):\n",
    "    global temp\n",
    "    frame = distance(frameA, frameB, frameT)\n",
    "    if frame:\n",
    "        if(frame.distance >= threshold):\n",
    "            if threshold == 1000:\n",
    "                threshold = frame.distance\n",
    "            else:\n",
    "                return\n",
    "        new_frameA = deepcopy(frameA)\n",
    "        #append the returned frame into the last index of frameA and delete the 1st index of frameA\n",
    "        new_frameA.append(deepcopy(frameT[frame.index]))\n",
    "        new_frameA.pop(0)\n",
    "        #append the returned frame into the last index of temp.\n",
    "        temp.append(frameT[frame.index])\n",
    "        frameT.pop(frame.index)\n",
    "        #recursively call the function\n",
    "        divide_right(new_frameA, frameB, frameT, threshold-120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R :  53.152127197451115\n",
    "R :  53.68161060096693\n",
    "R :  62.17241731286414\n",
    "R :  63.13998703209069\n",
    "R :  48.942293057706124\n",
    "R :  35.5034735443986\n",
    "R :  33.38878473335145\n",
    "R :  38.92210931101864\n",
    "R :  38.31790376278826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a function to read the video frames\n",
    "def readVideo(vid):\n",
    "    cap = vid\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    buf = np.empty((frameCount, 800, 900, 3), np.dtype('uint8'))\n",
    "    fc = 0\n",
    "    ret = True\n",
    "\n",
    "    while (fc < frameCount  and ret):\n",
    "        ret, temp = cap.read()\n",
    "        #crop the frame. for x from 500 to 1400, y from 0 to 800\n",
    "        buf[fc] = temp[0:800,500:1400]\n",
    "        fc += 1\n",
    "\n",
    "    cap.release()\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to read the video frames from the transition because transition has a big data, so cannot store everything in the array\n",
    "def readLargeVideo(vid, trans_idx):\n",
    "    cap = vid\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    buf = np.empty((len(trans_idx), 800, 900, 3), np.dtype('uint8'))\n",
    "    \n",
    "    fc = 0\n",
    "    ret = True\n",
    "\n",
    "    while (fc < frameCount  and ret):\n",
    "        ret, temp = cap.read()\n",
    "        for i in range(len(trans_idx)):\n",
    "            #if the current readed frame index is same with the transition frame number then fill the array\n",
    "            if fc == trans_idx[i].frameNumber:\n",
    "                buf[i] = temp[0:800,500:1400]\n",
    "        fc += 1\n",
    "    cap.release()\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data():\n",
    "    global temp\n",
    "    threshold = inputSlider.get()\n",
    "    text = inputText.get()\n",
    "    input_text = text.split(\" \")\n",
    "    #call the function defined before\n",
    "    trans = LoadTransition()\n",
    "    #to measure the time\n",
    "    start = time.time()\n",
    "    #define json files basepath\n",
    "    dir_path = \"../jsons/\"\n",
    "    words = []\n",
    "    for i in range(len(input_text)):\n",
    "        ctr = 0\n",
    "        words.append([])\n",
    "        for filename in os.listdir(dir_path+input_text[i]):\n",
    "            if input_text[i] in filename:\n",
    "                number = int(re.split(\"(\\d+)\", os.path.basename(filename))[1])\n",
    "\n",
    "                #3 is the n from n-frames. get the 3 first and 3 last frames from a gloss. so 1 array contain 6 frames.\n",
    "                if (number < 3 or number >= len(os.listdir(dir_path+input_text[i]))-3):\n",
    "                    words[i].append(Points())\n",
    "                    with open(dir_path +input_text[i]+\"/\"+input_text[i]+\"_\"+ ((str)(number)).zfill(12)+\"_keypoints.json\") as df:\n",
    "                        data = json.load(df)\n",
    "                        xLeft = []; yLeft = []; xRight = []; yRight = []\n",
    "\n",
    "                        for j in range(4,21,4):\n",
    "                            xLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3])\n",
    "                            yLeft.append(data['people'][0]['hand_left_keypoints_2d'][j*3+1])\n",
    "                            xRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3])\n",
    "                            yRight.append(data['people'][0]['hand_right_keypoints_2d'][j*3+1])\n",
    "                        for j in range(1,5):\n",
    "                            words[i][ctr].lOrientation.append(np.cross([xLeft[0] , yLeft[0]] ,[xLeft[j] , yLeft[j]]))\n",
    "                            words[i][ctr].rOrientation.append(np.cross([xRight[0], yRight[0]],[xRight[j],yRight[j]]))\n",
    "\n",
    "                        words[i][ctr].xBody.append(data['people'][0]['pose_keypoints_2d'][4*3])\n",
    "                        words[i][ctr].xBody.append(data['people'][0]['pose_keypoints_2d'][7*3])\n",
    "                        words[i][ctr].yBody.append(data['people'][0]['pose_keypoints_2d'][4*3+1])\n",
    "                        words[i][ctr].yBody.append(data['people'][0]['pose_keypoints_2d'][7*3+1])\n",
    "                        words[i][ctr].frameNumber = number \n",
    "\n",
    "                        words[i][ctr].xPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][0])\n",
    "                        words[i][ctr].yPalmLeft = (data['people'][0]['hand_left_keypoints_2d'][1])\n",
    "                        words[i][ctr].xPalmRight = (data['people'][0]['hand_right_keypoints_2d'][0])\n",
    "                        words[i][ctr].yPalmRight = (data['people'][0]['hand_right_keypoints_2d'][1])\n",
    "\n",
    "                        words[i][ctr].xLCenter = np.sum(xLeft)/np.count_nonzero(xLeft)\n",
    "                        words[i][ctr].xRCenter = np.sum(xRight)/np.count_nonzero(xRight)\n",
    "                        words[i][ctr].yLCenter = np.sum(yLeft)/np.count_nonzero(yLeft)\n",
    "                        words[i][ctr].yRCenter = np.sum(yRight)/np.count_nonzero(yRight)\n",
    "\n",
    "                        ctr+=1\n",
    "                        \n",
    "\n",
    "\n",
    "    for i in range(0, len(words)-1):\n",
    "        frameA = []\n",
    "        frameB = []\n",
    "        #arrange frameA and frameB content\n",
    "        for j in range(0, (int)(len(words[i])/2)):\n",
    "            frameA.append(deepcopy(words[i][(int)(len(words[i])/2)+j]))\n",
    "        for j in range(0, (int)(len(words[i+1])/2)):\n",
    "            frameB.append(deepcopy(words[i+1][j]))\n",
    "        #call divide left and divide right\n",
    "        divide_left(frameA,frameB,deepcopy(trans), threshold)\n",
    "        divide_right(frameA,frameB,deepcopy(trans), threshold)\n",
    "        transition.append(temp.copy())\n",
    "        temp = []\n",
    "        \n",
    "    #read gloss video and save to array of images\n",
    "    videos = []\n",
    "    for i in range(len(input_text)):\n",
    "        videos.append(readVideo(cv2.VideoCapture('./ASL/'+input_text[i]+'.mp4')))\n",
    "        \n",
    "    #read transition video and save to array of images\n",
    "    written_trans = []\n",
    "    for i in range(0, len(transition)):\n",
    "        written_trans.append([])\n",
    "        written_trans[i] = (readLargeVideo(cv2.VideoCapture('./ASL/transitions.mp4'),transition[i]))\n",
    "        \n",
    "    #arrange the output frames from the separated array of frames\n",
    "    output = []\n",
    "    for i in range(0, len(input_text)):\n",
    "        for j in range(0, len(videos[i])):\n",
    "            output.append(videos[i][j])\n",
    "        if i < len(input_text)-1:\n",
    "            prev = videos[i][j]\n",
    "            for j in range(0, len(written_trans[i])):\n",
    "                if j > 0:\n",
    "                    prev = written_trans[i][j-1]\n",
    "                output.append(trans_smoothing(prev, written_trans[i][j], 0.5))\n",
    "                output.append(written_trans[i][j])\n",
    "                \n",
    "    #write the video\n",
    "    height,width,channels = videos[0][0].shape\n",
    "    out = cv2.VideoWriter('outputThesis/output.mp4',cv2.VideoWriter_fourcc('F','M','P', '4'), 10, (width,height))\n",
    "    for i in range(0, len(output)):\n",
    "            out.write(output[i])\n",
    "    out.release()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Time for processing: \"+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for processing: 59.02824640274048\n"
     ]
    }
   ],
   "source": [
    "root = Tk()\n",
    "root.title(\"Text to ASL Video\")\n",
    "root.geometry(\"500x100\") #You want the size of the app to be 500x500\n",
    "root.resizable(0, 0) #Don't allow resizing in the x or y direction\n",
    "inputText = Entry(root)\n",
    "inputText.pack()\n",
    "inputSlider = Scale(root, from_=0, to=2000, orient=HORIZONTAL)\n",
    "inputSlider.pack()\n",
    "Button(root, text=\"Get ASL Result\", command=set_data).pack()\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
